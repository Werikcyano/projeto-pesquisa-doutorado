@article{f8a2dca1e8fe56e698984c077f7ff58d8ca867e9,
title = {Large Language Models as Optimizers},
year = {2023},
url = {https://www.semanticscholar.org/paper/f8a2dca1e8fe56e698984c077f7ff58d8ca867e9},
author = {Chengrun Yang and Xuezhi Wang and Yifeng Lu and Hanxiao Liu and Quoc V. Le and Denny Zhou and Xinyun Chen},
journal = {ArXiv},
volume = {abs/2309.03409},
doi = {10.48550/arXiv.2309.03409},
arxivid = {2309.03409},
}

@article{3eee1fe6acf9760efa215130617a4f13d32b4962,
title = {ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling},
year = {2025},
url = {https://www.semanticscholar.org/paper/3eee1fe6acf9760efa215130617a4f13d32b4962},
abstract = {Formulating optimization problems for industrial applications demands significant manual effort and domain expertise. While Large Language Models (LLMs) show promise in automating this process, evaluating their performance remains difficult due to the absence of robust metrics. Existing solver-based approaches often face inconsistency, infeasibility issues, and high computational costs. To address these issues, we propose ORGEval, a graph-theoretic evaluation framework for assessing LLMs'capabilities in formulating linear and mixed-integer linear programs. ORGEval represents optimization models as graphs, reducing equivalence detection to graph isomorphism testing. We identify and prove a sufficient condition, when the tested graphs are symmetric decomposable (SD), under which the Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism. Building on this, ORGEval integrates a tailored variant of the WL-test with an SD detection algorithm to evaluate model equivalence. By focusing on structural equivalence rather than instance-level configurations, ORGEval is robust to numerical variations. Experimental results show that our method can successfully detect model equivalence and produce 100\% consistent results across random parameter configurations, while significantly outperforming solver-based methods in runtime, especially on difficult problems. Leveraging ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs on optimization modeling. Our results reveal that although optimization modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4 achieve the highest accuracies under direct prompting, outperforming even leading reasoning models.},
author = {Zhuohan Wang and Ziwei Zhu and Ziniu Li and Congliang Chen and Yizhou Han and Yufeng Lin and Zhihang Lin and Angyang Gu and Xinglin Hu and Ruoyu Sun and Tian Ding},
journal = {ArXiv},
volume = {abs/2510.27610},
pages = {null},
doi = {10.48550/arXiv.2510.27610},
arxivid = {2510.27610},
}

@article{778043fc3a09a9dc96a748843bce59a5e0db2ed4,
title = {Large Language Models in Operations Research: Methods, Applications, and Challenges},
year = {2025},
url = {https://www.semanticscholar.org/paper/778043fc3a09a9dc96a748843bce59a5e0db2ed4},
abstract = {Operations research (OR) is a core methodology that supports complex system decision-making, with broad applications in transportation, supply chain management, and production scheduling. However, traditional approaches that rely on expert-driven modeling and manual parameter tuning often struggle with large-scale, dynamic, and multi-constraint problems, limiting scalability and real-time applicability. Large language models (LLMs), with capabilities in semantic understanding, structured generation, and reasoning control, offer new opportunities to overcome these challenges. They can translate natural language problem descriptions into mathematical models or executable code, generate heuristics, evolve algorithms, and directly solve optimization tasks. This shifts the paradigm from human-driven processes to intelligent human-AI collaboration. This paper systematically reviews progress in applying LLMs to OR, categorizing existing methods into three pathways: automatic modeling, auxiliary optimization, and direct solving. It also examines evaluation benchmarks and domain-specific applications, and highlights key challenges, including unstable semantic-to-structure mapping, fragmented research, limited generalization and interpretability, insufficient evaluation systems, and barriers to industrial deployment. Finally, it outlines potential research directions. Overall, LLMs demonstrate strong potential to reshape the OR paradigm by enhancing interpretability, adaptability, and scalability, paving the way for next-generation intelligent optimization systems.},
author = {Yang Wang and Kai Li},
arxivid = {2509.18180},
}

@article{1b6e810ce0afd0dd093f789d2b2742d047e316d5,
title = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
year = {2022},
url = {https://www.semanticscholar.org/paper/1b6e810ce0afd0dd093f789d2b2742d047e316d5},
author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed H. Chi and F. Xia and Quoc Le and Denny Zhou},
journal = {ArXiv},
volume = {abs/2201.11903},
arxivid = {2201.11903},
}

@article{bbe2f0a73e8bac09457ea17d3b6276dc97f170df,
title = {Large Language Models for Supply Chain Optimization},
year = {2023},
url = {https://www.semanticscholar.org/paper/bbe2f0a73e8bac09457ea17d3b6276dc97f170df},
author = {Beibin Li and Konstantina Mellou and Bo-qing Zhang and Jeevan Pathuri and Ishai Menache},
journal = {ArXiv},
volume = {abs/2307.03875},
doi = {10.48550/arXiv.2307.03875},
arxivid = {2307.03875},
}

@article{1c259361caa85c2d95a7d04e5e42fa98693da85b,
title = {Large Language Models as Evolutionary Optimizers},
year = {2023},
url = {https://www.semanticscholar.org/paper/1c259361caa85c2d95a7d04e5e42fa98693da85b},
author = {Shengcai Liu and Caishun Chen and Xinghua Qu and Ke Tang and Y. Ong},
journal = {2024 IEEE Congress on Evolutionary Computation (CEC)},
doi = {10.1109/CEC60901.2024.10611913},
arxivid = {2310.19046},
}

@article{074299c38fe2f099d970d92eafc592a6706035c6,
title = {CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling},
year = {2025},
url = {https://www.semanticscholar.org/paper/074299c38fe2f099d970d92eafc592a6706035c6},
abstract = {Large Reasoning Models (LRMs) have demonstrated strong capabilities in complex multi-step reasoning, opening new opportunities for automating optimization modeling. However, existing domain adaptation methods, originally designed for earlier instruction-tuned models, often fail to exploit the advanced reasoning patterns of modern LRMs -- In particular, we show that direct fine-tuning on traditional \textit{non-reflective} datasets leads to limited gains. To fully leverage LRMs'inherent reasoning abilities, we propose \textbf{CALM} (\textit{Corrective Adaptation with Lightweight Modification}), a framework that progressively refines LRMs within their native reasoning modes for optimization modeling tasks. In CALM, an expert intervener identifies reasoning flaws and provides concise corrective hints, which the LRM incorporates to produce improved reasoning trajectories. These interventions modify fewer than 2.6\% of generated tokens, but generate high-quality data for soft adaptation through supervised fine-tuning. The adapted model is then further improved through reinforcement learning. Building on CALM, we develop \textbf{STORM} (\textit{Smart Thinking Optimization Reasoning Model}), a 4B-parameter LRM that achieves a new state-of-the-art average accuracy of 68.9\% across five popular optimization modeling benchmarks, matching the performance of a 671B LRM. These results demonstrate that dynamic, hint-based data synthesis both preserves and amplifies the native reasoning patterns of modern LRMs, offering a more effective and scalable path towards expert-level performance on challenging optimization modeling tasks.},
author = {Zhengyang Tang and Zihan Ye and Chenyu Huang and Xuhan Huang and Chengpeng Li and Sihang Li and Guanhua Chen and Ming Yan and Zizhuo Wang and Hongyuan Zha and Dayiheng Liu and Benyou Wang},
journal = {ArXiv},
volume = {abs/2510.04204},
pages = {null},
doi = {10.48550/arXiv.2510.04204},
arxivid = {2510.04204},
}

@article{2fe6060ced80c1c245a718e6188b6516207bf0a8,
title = {Augmenting Operations Research with Auto-Formulation of Optimization Models from Problem Descriptions},
year = {2022},
url = {https://www.semanticscholar.org/paper/2fe6060ced80c1c245a718e6188b6516207bf0a8},
author = {Rindranirina Ramamonjison and Haley Li and Timothy T. L. Yu and Shiqi He and Vishnu Rengan and Amin Banitalebi-Dehkordi and Zirui Zhou and Yong Zhang},
journal = {ArXiv},
volume = {abs/2209.15565},
doi = {10.48550/arXiv.2209.15565},
arxivid = {2209.15565},
}

@article{204e3073870fae3d05bcbc2f6a8e263d9b72e776,
title = {Attention is All you Need},
year = {2017},
url = {https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776},
author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and I. Polosukhin},
arxivid = {1706.03762},
}

@article{be7a88babf78512b545f585517704cb597388cbc,
title = {ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution},
year = {2024},
url = {https://www.semanticscholar.org/paper/be7a88babf78512b545f585517704cb597388cbc},
author = {Haoran Ye and Jiarui Wang and Zhiguang Cao and Guojie Song},
journal = {ArXiv},
volume = {abs/2402.01145},
doi = {10.48550/arXiv.2402.01145},
arxivid = {2402.01145},
}

@article{6f99bcc23e8308650dae64970980bdeae2a4f9d2,
title = {AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library},
year = {2025},
url = {https://www.semanticscholar.org/paper/6f99bcc23e8308650dae64970980bdeae2a4f9d2},
author = {Minwei Kong and Ao Qu and Xiaotong Guo and Wenbin Ouyang and Chonghe Jiang and Han Zheng and Yining Ma and Dingyi Zhuang and Yuhan Tang and Junyi Li and Hai Wang and Cathy Wu and Jinhua Zhao},
journal = {ArXiv},
volume = {abs/2510.18428},
doi = {10.48550/arXiv.2510.18428},
arxivid = {2510.18428},
}

@article{92b39ce69cc1ee59aff8a92f30557728edc6ea32,
title = {OptiMind: Teaching LLMs to Think Like Optimization Experts},
year = {2025},
url = {https://www.semanticscholar.org/paper/92b39ce69cc1ee59aff8a92f30557728edc6ea32},
author = {Zeyi Chen and Xinzhi Zhang and Humishka Zope and Hugo Barbalho and Konstantina Mellou and Marco Molinaro and Janardhan Kulkarni and Ishai Menache and Sirui Li},
journal = {ArXiv},
volume = {abs/2509.22979},
doi = {10.48550/arXiv.2509.22979},
arxivid = {2509.22979},
}

@article{04eb39fb141f058081036a3c65610c59cd781792,
title = {OptiChat: Bridging Optimization Models and Practitioners with Large Language Models},
year = {2025},
url = {https://www.semanticscholar.org/paper/04eb39fb141f058081036a3c65610c59cd781792},
author = {Hao Chen and Gonzalo E. Constante-Flores and Krishna Sri Ipsit Mantri and Sai Madhukiran Kompalli and A. Ahluwalia and Can Li},
journal = {ArXiv},
volume = {abs/2501.08406},
doi = {10.48550/arXiv.2501.08406},
arxivid = {2501.08406},
}

