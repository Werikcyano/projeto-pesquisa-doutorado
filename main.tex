\documentclass[12pt,a4paper]{article}

% Configurações de pacotes
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{times} % Times New Roman
\usepackage{setspace} % Controle de espaçamento
\usepackage{geometry} % Margens
\usepackage{titlesec} % Formatação de títulos
\usepackage{titling} % Controle da capa
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[numbers]{natbib} % Citações numéricas (estilo comum em engenharia)
\usepackage{url}
\usepackage{hyperref}
\usepackage{tabularx} % Para tabelas melhores
\usepackage{booktabs} % Para linhas de tabelas profissionais
\usepackage{tikz} % Para esquemáticos se necessário
\usetikzlibrary{shapes,arrows,positioning}

% Configurações de página
\geometry{
    a4paper,
    left=3cm,
    top=3cm,
    right=2cm,
    bottom=2cm
}

% Espaçamento entre linhas: 1.5
\onehalfspacing

% Configuração de títulos
\titleformat{\section}
    {\normalfont\fontsize{12}{18}\bfseries}
    {\thesection}{1em}{}
    
\titleformat{\subsection}
    {\normalfont\fontsize{12}{18}\bfseries}
    {\thesubsection}{1em}{}

% Remover numeração de páginas na capa
\pagenumbering{gobble}

% ============================================
% CAPA
% ============================================
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{1cm}
    
    {\bfseries PROGRAMA DE PÓS-GRADUAÇÃO EM ENGENHARIA ELÉTRICA\\E DE COMPUTAÇÃO}\\[0.2cm]
    {\bfseries UNIVERSIDADE FEDERAL DE GOIÁS}\\[1cm]
    
    \vspace{4cm}
    
    {\Large\bfseries Agentes Cognitivos Colaborativos para Refinamento Iterativo de Modelos de Decisão em Engenharia Sob Incerteza}\\[2cm]
    
    \vspace{3cm}
    
    {\large Candidato: Werikcyano Lima Guimarães}\\[0.3cm]
    {\large Orientador: Leonardo da Cunha Brito}\\[0.5cm]
    
    \vfill
    
    {\large Goiânia}\\[0.2cm]
    {\large 2026}
    
\end{titlepage}

% Nova página após a capa
\newpage

% A partir daqui, numeração de páginas e sem identificação
\pagenumbering{arabic}
\setcounter{page}{1}

% ============================================
% INTRODUÇÃO E JUSTIFICATIVA
% ============================================
\section{Introdução e Justificativa}

\subsection{Contexto e Motivação}

A complexidade inerente aos sistemas de engenharia contemporâneos, particularmente no âmbito do setor elétrico e de energia, demanda o emprego de modelos de otimização sofisticados para subsidiar processos decisórios sob condições de incerteza. Tradicionalmente, a transposição de requisitos operacionais para formulações matemáticas rigorosas constitui uma atividade de alta especialização técnica, exigindo competências em pesquisa operacional que raramente coincidem com o conhecimento de campo dos engenheiros de domínio. Observa-se, com frequência, uma dissociação entre a intuição prática e a formalização necessária para a utilização de ferramentas computacionais avançadas. Tal cenário é agravado pela natureza tácita de parcela significativa das restrições operacionais — regras fundamentadas na experiência empírica que raramente são capturadas em especificações de requisitos formais, mas que são críticas para a integridade e segurança dos sistemas.

\subsection{Fundamentação e Estado da Arte}

O advento dos Modelos de Linguagem de Grande Escala (LLMs) propiciou uma mudança de paradigma na automação da modelagem matemática. Propostas seminais evidenciam a capacidade dessas ferramentas em atuar como interfaces entre a linguagem natural e solvers de otimização, promovendo ganhos significativos em acessibilidade e transparência \citep{bbe2f0a73e8bac09457ea17d3b6276dc97f170df}. A literatura recente descreve uma transição de processos puramente orientados por especialistas para ambientes de colaboração inteligente entre humanos e inteligência artificial \citep{778043fc3a09a9dc96a748843bce59a5e0db2ed4}.

Investigações sobre o uso de LLMs como mecanismos de otimização direta, como a metodologia \textit{Optimization by PROmpting} (OPRO), demonstram que modelos de linguagem podem gerar e refinar soluções iterativamente ao analisar o histórico de desempenhos anteriores \citep{f8a2dca1e8fe56e698984c077f7ff58d8ca867e9}. Adicionalmente, o desenvolvimento de sistemas de diálogo como o \textit{OptiChat} busca aproximar os modelos de otimização dos profissionais de campo, permitindo diagnósticos de inviabilidade e análises de sensibilidade por meio de interações em linguagem natural \citep{04eb39fb141f058081036a3c65610c59cd781792}.

\subsection{Lacunas de Pesquisa e Justificativa}

Contudo, a aplicação dessas tecnologias em ambientes de engenharia crítica permanece limitada por desafios fundamentais. A literatura aponta que a precisão das formulações geradas por LLMs ainda é prejudicada pela escassez de dados de treinamento que integrem efetivamente o conhecimento de domínio específico \citep{92b39ce69cc1ee59aff8a92f30557728edc6ea32}. Observa-se uma instabilidade recorrente no mapeamento entre a semântica da linguagem natural e a estrutura matemática formal, o que pode resultar em modelos sintaticamente corretos, mas semanticamente inviáveis ou perigosos para a operação real \citep{778043fc3a09a9dc96a748843bce59a5e0db2ed4}.

A ausência de mecanismos robustos de verificação que atuem em tempo de execução representa uma lacuna crítica. Sistemas que dependem exclusivamente de \textit{prompting} estático falham em capturar as sutilezas das normas de segurança e restrições físicas de sistemas elétricos. Existe, portanto, uma necessidade premente de arquiteturas que não apenas automatizem a modelagem, mas que incorporem processos de crítica e correção baseados em princípios de engenharia, garantindo a confiabilidade indispensável em setores de infraestrutura crítica.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=3cm, 
        auto,
        every node/.style={font=\footnotesize},
        block/.style={rectangle, draw, rounded corners, fill=blue!10, text width=2.8cm, align=center, minimum height=1.2cm},
        human/.style={ellipse, draw, fill=green!10, text width=2.5cm, align=center},
        line/.style={draw, -latex', thick}
    ]

        % Cenário Tradicional
        \node[human] (eng) {Engenheiro Especialista};
        \node[block, right=2.5cm of eng] (manual) {Formulação Manual (Matemática/Código)};
        \node[block, right=2cm of manual] (solver) {Solver de Otimização};
        
        % Labels
        \node[above=0.2cm of manual, font=\bfseries] {Abordagem Tradicional};
        
        \path[line] (eng) -- node[midway, above] {Conhecimento} (manual);
        \path[line] (manual) -- (solver);
        \path[line, dashed] (solver) -- ++(0,-1.8) -| node[pos=0.25, below] {Erro/Feedback Manual} (eng);

        % Cenário Proposto (human-in-the-loop)
        \node[human, below=4.5cm of eng] (eng2) {Engenheiro Especialista};
        \node[block, right=2.5cm of eng2, fill=orange!10] (mas) {\textbf{Agentes Colaborativos} (Formulador + Crítico)};
        \node[block, right=2cm of mas] (solver2) {Solver de Otimização};

        % Labels
        \node[above=0.7cm of mas, font=\bfseries] {Abordagem Proposta};

        % Usando setas curvas para separar os fluxos e evitar sobreposição
        % Fluxo Engenheiro <-> Agentes
        \path[line] (eng2) edge[bend left=20] node[midway, above] {Linguagem Natural} (mas);
        \path[line, dashed] (mas) edge[bend left=20] node[midway, below] {Refinamento} (eng2);

        % Fluxo Agentes <-> Solver
        \path[line] (mas) edge[bend left=20] node[midway, above] {Modelo} (solver2);
        \path[line] (solver2) edge[bend left=20] node[midway, below] {Viabilidade} (mas);

    \end{tikzpicture}
    \caption{Comparativo conceitual: (Superior) O fluxo tradicional exige tradução manual. (Inferior) A abordagem proposta utiliza agentes intermediários (setas curvas representam o fluxo contínuo de ida e volta).}
    \label{fig:comparativo_abordagens}
\end{figure}

\subsection{A Abordagem Proposta: Agentes Cognitivos Colaborativos}

Esta proposta de doutorado busca superar tais limitações por meio do desenvolvimento de uma arquitetura baseada em Sistemas Multi-Agentes (MAS), fundamentada na colaboração entre agentes cognitivos especializados e o engenheiro humano. Propõe-se um fluxo de refinamento iterativo sustentado por um Agente Formulador e um Agente Crítico, conforme ilustrado na Figura \ref{fig:comparativo_abordagens}. O diagrama evidencia a mudança de paradigma em relação ao método tradicional: ao invés de atuar isoladamente na tradução matemática, o engenheiro supervisiona um sistema inteligente que realiza a formulação e a verificação prévia, reduzindo a carga cognitiva e o risco de erros de modelagem. 

Diferente de abordagens unilaterais, o sistema operará como uma biblioteca de experiências que se aprimora continuamente a partir do \textit{feedback} de solvers e da interação humana \citep{6f99bcc23e8308650dae64970980bdeae2a4f9d2}. Ao integrar metodologias de raciocínio estruturado \citep{1b6e810ce0afd0dd093f789d2b2742d047e316d5} e processos de adaptação corretiva com intervenção mínima \citep{074299c38fe2f099d970d92eafc592a6706035c6}, o arcabouço proposto visa transformar a modelagem matemática em um diálogo colaborativo, capaz de explicitar e formalizar o conhecimento tácito essencial para a engenharia de energia.

% ============================================
% OBJETIVOS
% ============================================
\section{Objetivos}

\subsection{Objetivo Geral}

O objetivo central desta tese de doutorado consiste em conceber, implementar e validar um arcabouço computacional baseado em Sistemas Multi-Agentes (MAS) para o refinamento colaborativo de modelos de otimização em engenharia. A pesquisa visa estabelecer um paradigma de interação \textit{Human-in-the-loop} que possibilite a conversão de requisitos em linguagem natural para formulações matemáticas rigorosas, garantindo a transparência, a viabilidade técnica e a captura de restrições operacionais tácitas em sistemas de infraestrutura crítica.

\subsection{Objetivos Específicos}

Para a consecução do objetivo geral, estabelecem-se os seguintes objetivos específicos:

\begin{itemize}
    \item \textbf{Arquitetura de Formulação Cognitiva:} Investigar e desenvolver um Agente Formulador fundamentado em Modelos de Linguagem de Grande Escala (LLMs) capaz de realizar o mapeamento semântico entre descrições informais de problemas de engenharia e linguagens de modelagem algébrica (e.g., Pyomo, GAML).
    \item \textbf{Mecanismo de Crítica e Verificação Semântica:} Projetar um Agente Crítico dotado de lógica de domínio específica para a auditoria automatizada de modelos, integrando retroalimentação de solvers de otimização para a identificação e correção de alucinações conceituais e inconsistências matemáticas.
    \item \textbf{Protocolo de Aprendizado Ativo e Elucidação:} Desenvolver um módulo de Aprendizado Ativo (\textit{Active Learning}) orientado à detecção de ambiguidades na especificação inicial do problema, permitindo que o sistema interpele o especialista humano de forma estratégica para explicitar restrições e objetivos implícitos.
    \item \textbf{Integração de Memória e Aprendizado Contínuo:} Implementar uma biblioteca de experiências e padrões de modelagem que permita ao sistema aprender com interações passadas, aumentando a robustez e a precisão das formulações em novos problemas de domínios correlatos.
    \item \textbf{Validação em Engenharia de Energia:} Avaliar o desempenho do arcabouço proposto por meio de estudos de caso reais no planejamento e operação de sistemas elétricos, utilizando métricas de acurácia de modelagem, redução de tempo de desenvolvimento e índices de confiança do usuário final.
\end{itemize}

% ============================================
% REFERENCIAL TEÓRICO
% ============================================
\section{Referencial Teórico}

A fundamentação teórica desta pesquisa perpassa pela convergência entre o processamento de linguagem natural e a pesquisa operacional, com ênfase na utilização de modelos generativos para a solução de problemas complexos de engenharia.

\subsection{Evolução dos Modelos de Linguagem e Raciocínio Estruturado}

O desenvolvimento da arquitetura Transformer consolidou um marco na computação ao introduzir mecanismos de atenção que permitem o processamento paralelo de sequências textuais \citep{204e3073870fae3d05bcbc2f6a8e263d9b72e776}. Diferente das arquiteturas recorrentes precedentes, o Transformer baseia-se no mecanismo de \textit{Scaled Dot-Product Attention}, definido matematicamente como:

\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{equation}

onde $Q$, $K$ e $V$ representam as matrizes de \textit{queries}, \textit{keys} e \textit{values}, respectivamente, e $d_k$ é a dimensão das chaves. Essa inovação possibilitou o surgimento de modelos com bilhões de parâmetros, como o GPT-3, que demonstram capacidades de aprendizado \textit{few-shot} sem a necessidade de ajuste fino extensivo \citep{90abbc2cf38462b954ae1b772fac9532e2ccd8b0}. 

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=1.5cm,
        auto,
        every node/.style={font=\scriptsize},
        layer/.style={rectangle, draw, fill=blue!5, text width=2.5cm, align=center, minimum height=0.8cm, rounded corners},
        arrow/.style={-latex', thick}
    ]
        % Fluxo Simplificado Transformer
        \node (input) {Input Embedding};
        \node[layer, above=0.5cm of input] (att) {Multi-Head Attn};
        \node[layer, above=0.5cm of att] (norm) {Add \& Norm};
        \node[layer, above=0.5cm of norm] (ffn) {Feed Forward};
        \node[layer, above=0.5cm of ffn] (norm2) {Add \& Norm};
        \node[above=0.5cm of norm2] (output) {Output Probabilities};
        
        % Conexões
        \draw[arrow] (input) -- (att);
        \draw[arrow] (att) -- (norm);
        \draw[arrow] (norm) -- (ffn);
        \draw[arrow] (ffn) -- (norm2);
        \draw[arrow] (norm2) -- (output);
        
        % Residual connections (simbólico)
        \draw[arrow, dashed, ->] (input.west) to[bend left=45] (norm.west);
        \draw[arrow, dashed, ->] (norm.west) to[bend left=45] (norm2.west);

        \node[right=0.5cm of ffn, text width=4cm, align=left] {
            \textbf{Mecanismo de Atenção}:\\
            Permite o processamento paralelo e captura de dependências de longo alcance.
        };
    \end{tikzpicture}
    \caption{Representação simplificada de um bloco Transformer, destacando o mecanismo de atenção que permite o processamento paralelo eficiente, base para modelos como GPT.}
    \label{fig:transformer_block}
\end{figure}

Subsequentemente, a introdução de técnicas de estímulo ao raciocínio em etapas, conhecidas como \textit{Chain of Thought} (CoT), permitiu que esses modelos decompusessem problemas lógicos complexos em sequências de passos intermediários. Pesquisas indicam que a habilidade de raciocínio emerge naturalmente em modelos de grande escala quando instigados por demonstrações de pensamento estruturado \citep{1b6e810ce0afd0dd093f789d2b2742d047e316d5}. Tal avanço é fundamental para a transposição de requisitos de engenharia, que frequentemente exigem múltiplas etapas de dedução lógica antes da formalização matemática final.

\subsection{Integração de LLMs na Pesquisa Operacional}

A aplicação de LLMs no domínio da otimização tem evoluído da simples tradução de texto para código em direção à atuação direta como otimizadores. Metodologias baseadas em \textit{Optimization by PROmpting} (OPRO) utilizam o modelo de linguagem para gerar e refinar soluções iterativamente, integrando no contexto do \textit{prompt} o histórico de soluções anteriores e seus respectivos desempenhos \citep{f8a2dca1e8fe56e698984c077f7ff58d8ca867e9}. O processo pode ser resumido pela geração de uma nova solução $x_{t+1}$ baseada em um \textit{meta-prompt} $P_t$ que contém os pares $\{(x_i, f(x_i))\}_{i=1}^t$.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=2.5cm,
        auto,
        every node/.style={font=\scriptsize},
        proc/.style={rectangle, draw, fill=red!5, text width=2cm, align=center, minimum height=1cm, rounded corners},
        data/.style={trapezium, draw, fill=yellow!10, text width=1.5cm, align=center, trapezium left angle=70, trapezium right angle=110},
        arrow/.style={-latex', thick}
    ]
        % Ciclo OPRO
        \node[proc] (llm) {LLM Optimizer};
        \node[data, right=1.5cm of llm] (sol) {Solução ($x_t$)};
        \node[proc, below=1.5cm of sol] (eval) {Avaliador ($f(x)$)};
        \node[data, left=1.5cm of eval] (hist) {Histórico ($x_i, y_i$)};
        
        % Fluxo
        \draw[arrow] (llm) -- node[midway, above] {Gera} (sol);
        \draw[arrow] (sol) -- (eval);
        \draw[arrow] (eval) -- node[midway, below] {Score} (hist);
        \draw[arrow] (hist) -- node[midway, left] {Meta-Prompt} (llm);
        
        \node[above=0.2cm of llm] {\textbf{Optimization by Prompting}};

    \end{tikzpicture}
    \caption{Ciclo de otimização OPRO: O LLM gera soluções baseadas em um meta-prompt que contém o histórico de tentativas anteriores e suas avaliações, atuando como um algoritmo evolutivo guiado por linguagem.}
    \label{fig:opro_cycle}
\end{figure}

Paralelamente, abordagens híbridas integram algoritmos evolutivos com o raciocínio semântico dos LLMs. O \textit{Reflective Evolution} (ReEvo) utiliza reflexões verbais como "gradientes linguísticos" para guiar a busca em espaços heurísticos, permitindo a evolução automática de algoritmos de busca sem intervenção humana direta \citep{be7a88babf78512b545f585517704cb597388cbc}.

A robustez desse processo de modelagem é fortalecida pela criação de bibliotecas de experiência autogeridas. O arcabouço \textit{AlphaOPT} propõe um ciclo de autoaperfeiçoamento onde o sistema reflete sobre falhas passadas para extrair \textit{insights} estruturados em quatro componentes: \textit{taxonomy} (classificação do erro), \textit{condition} (contexto de ocorrência), \textit{explanation} (causa raiz) e \textit{example} (solução corrigida) \citep{6f99bcc23e8308650dae64970980bdeae2a4f9d2}. Essa estrutura de memória é vital para evitar a reincidência de erros semânticos em formulações de engenharia crítica, onde a precisão das restrições é determinante para a viabilidade operacional.

\subsection{Sistemas de Diálogo e Interpretabilidade em Engenharia}

A aceitação de sistemas baseados em inteligência artificial no ambiente industrial depende intrinsecamente da transparência das decisões propostas. Iniciativas como o \textit{OptiChat} estabelecem sistemas de diálogo em linguagem natural que permitem a profissionais realizar diagnósticos de inviabilidade, análises de sensibilidade e explicações contrafatuais sem a necessidade de perícia em modelagem algébrica \citep{04eb39fb141f058081036a3c65610c59cd781792}. A Figura \ref{fig:optichat_overview} ilustra a arquitetura deste sistema.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=1.0cm,
        auto,
        every node/.style={font=\tiny},
        input/.style={rectangle, draw=blue!50, fill=blue!5, text width=2cm, align=center, rounded corners, minimum height=0.8cm},
        output/.style={rectangle, draw=green!50, fill=green!5, text width=2cm, align=center, rounded corners, minimum height=0.8cm},
        core/.style={rectangle, draw=purple!50, fill=purple!5, text width=1.5cm, align=center, rounded corners, minimum height=1.5cm, font=\bfseries\scriptsize},
        backend/.style={rectangle, draw=gray!80, thick, text width=2.2cm, align=center, rounded corners, minimum height=1cm},
        group/.style={draw=gray!50, dashed, inner sep=0.2cm, rounded corners}
    ]
        % (a) User Interface
        \node[core] (llm) {LLM};
        
        \node[input, left=1.0cm of llm, yshift=0.8cm] (agnostic) {Solution-agnostic\\Query};
        \node[input, left=1.0cm of llm, yshift=-0.8cm] (specific) {Solution-specific\\Query};
        
        \node[output, right=1.0cm of llm, yshift=0.8cm] (qualitative) {Qualitative\\Explanation};
        \node[output, right=1.0cm of llm, yshift=-0.8cm] (feedback) {Technical\\Feedback};
        
        % Conexões (a)
        \draw[-latex, blue!50, thick] (agnostic.east) -- (llm.west);
        \draw[-latex, blue!50, thick] (specific.east) -- (llm.west);
        \draw[-latex, green!50, thick] (llm.east) -- (qualitative.west);
        \draw[-latex, green!50, thick] (llm.east) -- (feedback.west);
        
        \node[above=1.5cm of llm, font=\bfseries\small] {(a) User Interface};

        % (b) Backend
        \node[below=1.5cm of llm] (interaction) {\textbf{Interaction}};
        \draw[<->, thick] (llm) -- (interaction);

        % Backend Tools
        \node[backend, below=0.5cm of interaction] (funcs) {\textbf{Predefined Functions}\\Restore Feasibility\\Analyze Sensitivity};
        \node[backend, below=0.2cm of funcs] (codegen) {\textbf{Code Generation}\\Counterfactual Expl.\\Unexpected Failure};
        
        \node[backend, left=0.5cm of funcs, text width=1.8cm, minimum height=2.5cm] (software) {\textbf{Modeling Software}\\(Model Code)};
        \node[backend, right=0.5cm of funcs, text width=1.8cm, minimum height=2.5cm] (solver) {\textbf{Optimization Solver}\\(Description)};
        
        \node[yshift=0.5cm, font=\bfseries\small] at (funcs.north) {(b) Backend System};

    \end{tikzpicture}
    \caption{Visão geral do OptiChat. Entradas em azul (consultas), saídas em verde (explicações) e ferramentas de backend em cinza. Adaptado de \citet{04eb39fb141f058081036a3c65610c59cd781792}.}
    \label{fig:optichat_overview}
\end{figure} 

O sistema \textit{OptiMind} avança essa fronteira ao integrar conhecimentos específicos da Pesquisa Operacional para guiar o LLM na formulação de modelos de programação linear inteira mista (MILP). Ao utilizar estratégias de inferência multi-turno e síntese de erros baseada em classes de problemas, o \textit{OptiMind} eleva a acurácia das formulações ao mitigar erros comuns de modelagem através de ciclos de retroalimentação entre o modelo e o \textit{solver} \citep{92b39ce69cc1ee59aff8a92f30557728edc6ea32}.

Para assegurar a validade científica das formulações geradas, metodologias rigorosas de avaliação tornam-se indispensáveis. O \textit{ORGEval} propõe um arcabouço baseado em teoria dos grafos para avaliar a equivalência entre modelos, reduzindo a detecção de similaridade ao teste de isomorfismo de grafos. Essa abordagem permite uma avaliação robusta contra variações numéricas e estruturais, garantindo que o modelo gerado pelo LLM seja matematicamente equivalente à formulação de referência, independentemente de variações na nomenclatura de variáveis ou ordens de restrições \citep{3eee1fe6acf9760efa215130617a4f13d32b4962}. Tal rigor é essencial para sistemas que operam em infraestruturas críticas, onde a integridade semântica do modelo é um requisito de segurança inegociável.

% ============================================
% METODOLOGIA
% ============================================
\section{Metodologia}

A metodologia proposta para a execução desta pesquisa estrutura-se em fases incrementais, fundamentadas no desenvolvimento e na validação de um sistema multi-agente para suporte à decisão em problemas de engenharia crítica.

\subsection{Arquitetura do Sistema de Agentes Colaborativos}

O arcabouço computacional será composto por dois agentes principais que interagem em um ambiente de refinamento iterativo. O Agente Formulador terá a responsabilidade de interpretar as descrições em linguagem natural fornecidas pelo usuário e convertê-las em modelos de otimização estruturados. Para tal, serão utilizadas técnicas de engenharia de prompt avançadas para garantir a correta definição de variáveis de decisão, funções objetivo e restrições.

O Agente Crítico atuará como um mecanismo de verificação semântica. Esse agente será equipado com uma base de conhecimento técnico específica do setor elétrico e ferramentas de execução de código para validar a sintaxe e a lógica do modelo proposto. Caso sejam detectadas inconsistências ou falhas de viabilidade reportadas pelos solvers de otimização, o Agente Crítico gerará relatórios de erro em linguagem natural para que o Agente Formulador realize os ajustes necessários.

\subsection{Fluxo de Interação Human-in-the-Loop}

A interação com o especialista humano ocorrerá por meio de um módulo de aprendizado ativo. Quando o sistema identificar ambiguidades que impeçam a formalização precisa do problema, interpelará o usuário com questões estruturadas para elucidar o conhecimento tácito. O processo iterativo de crítica e formulação será mantido até que um modelo viável e validado seja obtido. A Figura \ref{fig:fluxo_agentes} ilustra o fluxo de informações proposto para a arquitetura do sistema.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[node distance=2cm, auto]
        \tikzstyle{block} = [rectangle, draw, fill=blue!10, text width=5em, text centered, rounded corners, minimum height=4em]
        \tikzstyle{cloud} = [ellipse, draw, fill=red!10, node distance=3cm, minimum height=2em]
        \tikzstyle{line} = [draw, -latex']
        
        \node [cloud] (user) {Engenheiro};
        \node [block, right of=user, node distance=4cm] (form) {Agente Formulador};
        \node [block, below of=form, node distance=3cm] (crit) {Agente Crítico};
        \node [block, left of=crit, node distance=4cm] (solv) {Solvers (Gurobi)};
        
        \path [line] (user) -- node {Requisitos} (form);
        \path [line] (form) -- node {Modelo} (crit);
        \path [line] (crit) -- node {Verificação} (solv);
        \path [line] (solv) -- node {Feedback} (crit);
        \path [line] (crit) -- node {Refinamento} (form);
        \path [line] (crit) -- node {Resultados} (user);
    \end{tikzpicture}
    \caption{Fluxograma simplificado da interação entre os agentes cognitivos e o especialista de domínio.}
    \label{fig:fluxo_agentes}
\end{figure}

\subsection{Cenário de Aplicação e Validação Experimental}

A validação do sistema proposto será realizada por meio de estudos de caso aplicados a problemas reais do setor elétrico brasileiro, como o planejamento da expansão de sistemas de transmissão ou a otimização do despacho de geração renovável. Serão utilizadas ferramentas de modelagem como Pyomo e solvers comerciais de alto desempenho, tais como Gurobi e CPLEX. O desempenho do sistema será avaliado com base na taxa de sucesso na geração de modelos viáveis, no tempo de convergência para o modelo final e na percepção de transparência e confiabilidade reportada por especialistas da área.

% ============================================
% CRONOGRAMA
% ============================================
\section{Cronograma}

O projeto de pesquisa será desenvolvido ao longo de um período de 48 meses, organizado em oito semestres letivos. O planejamento das atividades prioriza o cumprimento dos créditos obrigatórios e a revisão bibliográfica inicial, seguidos pelas etapas de desenvolvimento, experimentação e redação da tese.

\begin{table}[ht]
\centering
\small
\begin{tabularx}{\textwidth}{|X|c|c|c|c|c|c|c|c|}
\hline
\textbf{Atividades / Semestre} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\ \hline
Créditos em Disciplinas e Revisão Bibliográfica & X & X & X & & & & & \\ \hline
Concepção e Projeto da Arquitetura Multi-Agente & & X & X & & & & & \\ \hline
Desenvolvimento dos Agentes Formulador e Crítico & & & X & X & X & & & \\ \hline
Integração de Módulos de Aprendizado Ativo & & & & X & X & & & \\ \hline
Exame de Qualificação & & & & & X & & & \\ \hline
Realização de Experimentos e Validação & & & & & X & X & X & \\ \hline
Análise de Resultados e Publicações & & & & X & X & X & X & \\ \hline
Redação e Defesa da Tese & & & & & & & X & X \\ \hline
\end{tabularx}
\caption{Cronograma de execução das atividades de doutorado previstas para o período 2026-2030.}
\end{table}

% ============================================
% REFERÊNCIAS
% ============================================
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
