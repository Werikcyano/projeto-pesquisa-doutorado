\documentclass[12pt,a4paper]{article}

% Configurações de pacotes
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{times} % Times New Roman
\usepackage{setspace} % Controle de espaçamento
\usepackage{geometry} % Margens
\usepackage{titlesec} % Formatação de títulos
\usepackage{titling} % Controle da capa
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[numbers]{natbib} % Citações numéricas (estilo comum em engenharia)
\usepackage{url}
\usepackage{hyperref}
\usepackage{tabularx} % Para tabelas melhores
\usepackage{booktabs} % Para linhas de tabelas profissionais
\usepackage{tikz} % Para esquemáticos se necessário
\usetikzlibrary{shapes,arrows,positioning}

% Configurações de página
\geometry{
    a4paper,
    left=3cm,
    top=3cm,
    right=2cm,
    bottom=2cm
}

% Espaçamento entre linhas: 1.5
\onehalfspacing

% Configuração de títulos
\titleformat{\section}
    {\normalfont\fontsize{12}{18}\bfseries}
    {\thesection}{1em}{}
    
\titleformat{\subsection}
    {\normalfont\fontsize{12}{18}\bfseries}
    {\thesubsection}{1em}{}

% Remover numeração de páginas na capa
\pagenumbering{gobble}

% ============================================
% CAPA
% ============================================
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{1cm}
    
    {\bfseries PROGRAMA DE PÓS-GRADUAÇÃO EM ENGENHARIA ELÉTRICA\\E DE COMPUTAÇÃO}\\[0.2cm]
    {\bfseries UNIVERSIDADE FEDERAL DE GOIÁS}\\[1cm]
    
    \vspace{4cm}
    
    {\Large\bfseries Agentes Cognitivos Colaborativos para Refinamento Iterativo de Modelos de Decisão em Engenharia Sob Incerteza}\\[2cm]
    
    \vspace{3cm}
    
    {\large Candidato: Werikcyano Lima Guimarães}\\[0.3cm]
    {\large Orientador: Leonardo da Cunha Brito}\\[0.5cm]
    
    \vfill
    
    {\large Goiânia}\\[0.2cm]
    {\large 2026}
    
\end{titlepage}

% Nova página após a capa
\newpage

% A partir daqui, numeração de páginas e sem identificação
\pagenumbering{arabic}
\setcounter{page}{1}

% ============================================
% INTRODUÇÃO E JUSTIFICATIVA
% ============================================
\section{Introdução e Justificativa}

\subsection{Contexto e Motivação}

A complexidade inerente aos sistemas de engenharia contemporâneos, particularmente no âmbito do setor elétrico e de energia, demanda o emprego de modelos de otimização sofisticados para subsidiar processos decisórios sob condições de incerteza. Tradicionalmente, a transposição de requisitos operacionais para formulações matemáticas rigorosas constitui uma atividade de alta especialização técnica, exigindo competências em pesquisa operacional que raramente coincidem com o conhecimento de campo dos engenheiros de domínio. Observa-se, com frequência, uma dissociação entre a intuição prática e a formalização necessária para a utilização de ferramentas computacionais avançadas. Tal cenário é agravado pela natureza tácita de parcela significativa das restrições operacionais — regras fundamentadas na experiência empírica que raramente são capturadas em especificações de requisitos formais, mas que são críticas para a integridade e segurança dos sistemas.

\subsection{Fundamentação e Estado da Arte}

O advento dos Modelos de Linguagem de Grande Escala (LLMs) propiciou uma mudança de paradigma na automação da modelagem matemática. Conforme sistematizado no levantamento de \citet{Xiao2024ASO}, propostas seminais evidenciam a capacidade dessas ferramentas em atuar como interfaces entre a linguagem natural e solvers de otimização, promovendo ganhos significativos em acessibilidade e transparência \citep{bbe2f0a73e8bac09457ea17d3b6276dc97f170df}. A literatura recente descreve uma transição de processos puramente orientados por especialistas para ambientes de colaboração inteligente entre humanos e inteligência artificial \citep{778043fc3a09a9dc96a748843bce59a5e0db2ed4}.

Investigações sobre o uso de LLMs como mecanismos de otimização direta, como a metodologia \textit{Optimization by PROmpting} (OPRO), demonstram que modelos de linguagem podem gerar e refinar soluções iterativamente ao analisar o histórico de desempenhos anteriores \citep{f8a2dca1e8fe56e698984c077f7ff58d8ca867e9}. Adicionalmente, o desenvolvimento de sistemas de diálogo como o \textit{OptiChat} busca aproximar os modelos de otimização dos profissionais de campo, permitindo diagnósticos de inviabilidade e análises de sensibilidade por meio de interações em linguagem natural \citep{04eb39fb141f058081036a3c65610c59cd781792}.

\subsection{Lacunas de Pesquisa e Justificativa}

Contudo, a aplicação dessas tecnologias em ambientes de engenharia crítica permanece limitada por desafios fundamentais. A literatura aponta que a precisão das formulações geradas por LLMs ainda é prejudicada pela escassez de dados de treinamento que integrem efetivamente o conhecimento de domínio específico \citep{92b39ce69cc1ee59aff8a92f30557728edc6ea32}. Observa-se uma instabilidade recorrente no mapeamento entre a semântica da linguagem natural e a estrutura matemática formal, o que pode resultar em modelos sintaticamente corretos, mas semanticamente inviáveis ou perigosos para a operação real \citep{778043fc3a09a9dc96a748843bce59a5e0db2ed4}.

A ausência de mecanismos robustos de verificação que atuem em tempo de execução representa uma lacuna crítica. Sistemas que dependem exclusivamente de \textit{prompting} estático falham em capturar as sutilezas das normas de segurança e restrições físicas de sistemas elétricos. Existe, portanto, uma necessidade premente de arquiteturas que não apenas automatizem a modelagem, mas que incorporem processos de crítica e correção baseados em princípios de engenharia, garantindo a confiabilidade indispensável em setores de infraestrutura crítica.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=3cm, 
        auto,
        every node/.style={font=\footnotesize},
        block/.style={rectangle, draw, rounded corners, fill=blue!10, text width=2.8cm, align=center, minimum height=1.2cm},
        human/.style={ellipse, draw, fill=green!10, text width=2.5cm, align=center},
        line/.style={draw, -latex', thick}
    ]

        % Cenário Tradicional
        \node[human] (eng) {Engenheiro Especialista};
        \node[block, right=2.5cm of eng] (manual) {Formulação Manual (Matemática/Código)};
        \node[block, right=2cm of manual] (solver) {Solver de Otimização};
        
        % Labels
        \node[above=0.2cm of manual, font=\bfseries] {Abordagem Tradicional};
        
        \path[line] (eng) -- node[midway, above] {Conhecimento} (manual);
        \path[line] (manual) -- (solver);
        \path[line, dashed] (solver) -- ++(0,-1.8) -| node[pos=0.25, below] {Erro/Feedback Manual} (eng);

        % Cenário Proposto (human-in-the-loop)
        \node[human, below=4.5cm of eng] (eng2) {Engenheiro Especialista};
        \node[block, right=2.5cm of eng2, fill=orange!10] (mas) {\textbf{Agentes Colaborativos} (Formulador + Crítico)};
        \node[block, right=2cm of mas] (solver2) {Solver de Otimização};

        % Labels
        \node[above=0.7cm of mas, font=\bfseries] {Abordagem Proposta};

        % Usando setas curvas para separar os fluxos e evitar sobreposição
        % Fluxo Engenheiro <-> Agentes
        \path[line] (eng2) edge[bend left=20] node[midway, above] {Linguagem Natural} (mas);
        \path[line, dashed] (mas) edge[bend left=20] node[midway, below] {Refinamento} (eng2);

        % Fluxo Agentes <-> Solver
        \path[line] (mas) edge[bend left=20] node[midway, above] {Modelo} (solver2);
        \path[line] (solver2) edge[bend left=20] node[midway, below] {Viabilidade} (mas);

    \end{tikzpicture}
    \caption{Comparativo conceitual: (Superior) O fluxo tradicional exige tradução manual. (Inferior) A abordagem proposta utiliza agentes intermediários (setas curvas representam o fluxo contínuo de ida e volta).}
    \label{fig:comparativo_abordagens}
\end{figure}

\subsection{A Abordagem Proposta: Agentes Cognitivos Colaborativos}

Esta proposta de doutorado busca superar tais limitações por meio do desenvolvimento de uma arquitetura baseada em Sistemas Multi-Agentes (MAS), fundamentada na colaboração entre agentes cognitivos especializados e o engenheiro humano. Propõe-se um fluxo de refinamento iterativo sustentado por um Agente Formulador e um Agente Crítico, conforme ilustrado na Figura \ref{fig:comparativo_abordagens}. O diagrama evidencia a mudança de paradigma em relação ao método tradicional: ao invés de atuar isoladamente na tradução matemática, o engenheiro supervisiona um sistema inteligente que realiza a formulação e a verificação prévia, reduzindo a carga cognitiva e o risco de erros de modelagem. 

Diferente de abordagens unilaterais, o sistema operará como uma biblioteca de experiências que se aprimora continuamente a partir do \textit{feedback} de solvers e da interação humana \citep{6f99bcc23e8308650dae64970980bdeae2a4f9d2}. Ao integrar metodologias de raciocínio estruturado \citep{1b6e810ce0afd0dd093f789d2b2742d047e316d5} e processos de adaptação corretiva com intervenção mínima \citep{074299c38fe2f099d970d92eafc592a6706035c6}, o arcabouço proposto visa transformar a modelagem matemática em um diálogo colaborativo, capaz de explicitar e formalizar o conhecimento tácito essencial para a engenharia de energia.

% ============================================
% OBJETIVOS
% ============================================
\section{Objetivos}

\subsection{Objetivo Geral}

O objetivo central desta tese de doutorado consiste em conceber, implementar e validar um arcabouço computacional baseado em Sistemas Multi-Agentes (MAS) para o refinamento colaborativo de modelos de otimização em engenharia. A pesquisa visa estabelecer um paradigma de interação \textit{Human-in-the-loop} que possibilite a conversão de requisitos em linguagem natural para formulações matemáticas rigorosas, garantindo a transparência, a viabilidade técnica e a captura de restrições operacionais tácitas em sistemas de infraestrutura crítica.

\subsection{Objetivos Específicos}

Para a consecução do objetivo geral, estabelecem-se os seguintes objetivos específicos:

\begin{itemize}
    \item \textbf{Arquitetura de Formulação Cognitiva:} Investigar e desenvolver um Agente Formulador fundamentado em Modelos de Linguagem de Grande Escala (LLMs) capaz de realizar o mapeamento semântico entre descrições informais de problemas de engenharia e linguagens de modelagem algébrica (e.g., Pyomo, GAML).
    \item \textbf{Mecanismo de Crítica e Verificação Semântica:} Projetar um Agente Crítico dotado de lógica de domínio específica para a auditoria automatizada de modelos, integrando retroalimentação de solvers de otimização para a identificação e correção de alucinações conceituais e inconsistências matemáticas.
    \item \textbf{Protocolo de Aprendizado Ativo e Elucidação:} Desenvolver um módulo de Aprendizado Ativo (\textit{Active Learning}) orientado à detecção de ambiguidades na especificação inicial do problema, permitindo que o sistema interpele o especialista humano de forma estratégica para explicitar restrições e objetivos implícitos.
    \item \textbf{Integração de Memória e Aprendizado Contínuo:} Implementar uma biblioteca de experiências e padrões de modelagem que permita ao sistema aprender com interações passadas, aumentando a robustez e a precisão das formulações em novos problemas de domínios correlatos.
    \item \textbf{Validação em Engenharia de Energia:} Avaliar o desempenho do arcabouço proposto por meio de estudos de caso reais no planejamento e operação de sistemas elétricos, utilizando métricas de acurácia de modelagem, redução de tempo de desenvolvimento e índices de confiança do usuário final.
\end{itemize}

% ============================================
% REFERENCIAL TEÓRICO
% ============================================
\section{Referencial Teórico}

A fundamentação teórica desta pesquisa perpassa pela convergência entre o processamento de linguagem natural e a pesquisa operacional, com ênfase na utilização de modelos generativos para a solução de problemas complexos de engenharia.

\subsection{Evolução dos Modelos de Linguagem e Raciocínio Estruturado}

O desenvolvimento da arquitetura Transformer consolidou um marco na computação ao introduzir mecanismos de atenção que permitem o processamento paralelo de sequências textuais (Figura \ref{fig:transformer_block}) \citep{204e3073870fae3d05bcbc2f6a8e263d9b72e776}. Diferente das arquiteturas recorrentes precedentes, o Transformer baseia-se no mecanismo de \textit{Scaled Dot-Product Attention}, definido matematicamente por
\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V,
\end{equation}

onde $Q$, $K$ e $V$ representam as matrizes de \textit{queries}, \textit{keys} e \textit{values}, respectivamente, e $d_k$ é a dimensão das chaves. Essa inovação possibilitou o surgimento de modelos com bilhões de parâmetros, como o GPT-3, que demonstram capacidades de aprendizado \textit{few-shot} sem a necessidade de ajuste fino extensivo \citep{90abbc2cf38462b954ae1b772fac9532e2ccd8b0}. 

\begin{figure}[ht]
    \centering
    % Define styles separately to keep code clean
    \tikzset{
        block/.style={rectangle, draw, rounded corners, align=center, minimum height=0.8cm, minimum width=2.5cm, font=\footnotesize},
        io/.style={block, fill=red!15}, % Input/Output/Embedding - Pinkish
        attn/.style={block, fill=orange!15}, % Attention - Orangeish
        ff/.style={block, fill=cyan!15}, % Feed Forward - Blueish
        norm/.style={block, fill=yellow!20}, % Add & Norm - Yellowish
        linear/.style={block, fill=gray!15}, % Linear - Gray
        softmax/.style={block, fill=green!15}, % Softmax - Green
        pe/.style={circle, draw, fill=white, inner sep=0pt, minimum size=0.6cm}, % Positional Encoding
        plus/.style={circle, draw, inner sep=0pt, minimum size=0.4cm, path picture={\draw[black] (path picture bounding box.south) -- (path picture bounding box.north) (path picture bounding box.west) -- (path picture bounding box.east);}}, % Plus sign
        container/.style={draw=gray, rounded corners, thick, dashed},
        arrow/.style={-latex, thick}
    }
    
    \begin{tikzpicture}[node distance=0.6cm, auto]
        
        % ===========================
        % ENCODER (Left Side)
        % ===========================
        
        \node (inputs) {Entradas};
        \node[io, above=0.3cm of inputs] (in_emb) {Embedding de\\Entrada};
        \node[plus, above=0.3cm of in_emb] (plus1) {};
        \node[pe, left=0.5cm of plus1] (pe1) {$\sim$};
        \node[left=0.1cm of pe1, font=\scriptsize, align=right] {Codificação\\Posicional};
        
        % Encoder Stack Container Start
        \node[coordinate, above=0.4cm of plus1] (enc_start) {};
        
        \node[attn, above=0.5cm of plus1] (mha1) {Atenção\\Multi-Cabeça};
        \node[norm, above=0.2cm of mha1] (norm1) {Soma \& Norm};
        
        \node[ff, above=0.4cm of norm1] (ff1) {Feed\\Forward};
        \node[norm, above=0.2cm of ff1] (norm2) {Soma \& Norm};
        
        % Box around stacks
        \node[container, fit=(mha1) (norm1) (ff1) (norm2), inner sep=0.3cm] (enc_box) {};
        \node[left=0.1cm of enc_box, font=\large] {$N\times$};
        
        % Connections Encoder
        \draw[arrow] (inputs) -- (in_emb);
        \draw[arrow] (in_emb) -- (plus1);
        \draw[arrow] (pe1) -- (plus1);
        \draw[arrow] (plus1) -- (mha1);
        \draw[arrow] (mha1) -- (norm1);
        \draw[arrow] (norm1) -- (ff1);
        \draw[arrow] (ff1) -- (norm2);
        
        % Residuals Encoder
        % (mha1 input) -> (norm1)
        \draw[arrow] (plus1.north) ++(0,0.15) -- ++(-1.6,0) |- (norm1.west);
        % (norm1 output) -> (norm2)
        \draw[arrow] (norm1.north) ++(0,0.15) -- ++(-1.6,0) |- (norm2.west);
        
        
        % ===========================
        % DECODER (Right Side)
        % ===========================
        
        \node[right=2.5cm of inputs] (outputs) {Saídas\\(Deslocadas à direita)};
        \node[io, above=0.3cm of outputs] (out_emb) {Embedding de\\Saída};
        \node[plus, above=0.3cm of out_emb] (plus2) {};
        \node[pe, right=0.5cm of plus2] (pe2) {$\sim$};
        \node[right=0.1cm of pe2, font=\scriptsize, align=left] {Codificação\\Posicional};
        
        \node[attn, above=0.5cm of plus2] (mmha) {Atenção Multi-Cabeça\\Mascarada};
        \node[norm, above=0.2cm of mmha] (norm3) {Soma \& Norm};
        
        \node[attn, above=0.4cm of norm3] (mha2) {Atenção\\Multi-Cabeça};
        \node[norm, above=0.2cm of mha2] (norm4) {Soma \& Norm};
        
        \node[ff, above=0.4cm of norm4] (ff2) {Feed\\Forward};
        \node[norm, above=0.2cm of ff2] (norm5) {Soma \& Norm};
        
        % Box around decoder stack
        \node[container, fit=(mmha) (norm3) (mha2) (norm4) (ff2) (norm5), inner sep=0.3cm] (dec_box) {};
        \node[right=0.1cm of dec_box, font=\large] {$N\times$};
        
        % Output Head
        \node[linear, above=0.4cm of norm5] (linear) {Linear};
        \node[softmax, above=0.2cm of linear] (softmax) {Softmax};
        \node[above=0.3cm of softmax, align=center] (out_prob) {Probabilidades\\de Saída};
        
        % Connections Decoder
        \draw[arrow] (outputs) -- (out_emb);
        \draw[arrow] (out_emb) -- (plus2);
        \draw[arrow] (pe2) -- (plus2);
        \draw[arrow] (plus2) -- (mmha);
        \draw[arrow] (mmha) -- (norm3);
        \draw[arrow] (norm3) -- (mha2);
        \draw[arrow] (mha2) -- (norm4);
        \draw[arrow] (norm4) -- (ff2);
        \draw[arrow] (ff2) -- (norm5);
        \draw[arrow] (norm5) -- (linear);
        \draw[arrow] (linear) -- (softmax);
        \draw[arrow] (softmax) -- (out_prob);
        
        % Residuals Decoder
        \draw[arrow] (plus2.north) ++(0,0.15) -- ++(1.6,0) |- (norm3.east);
        \draw[arrow] (norm3.north) ++(0,0.15) -- ++(1.6,0) |- (norm4.east);
        \draw[arrow] (norm4.north) ++(0,0.15) -- ++(1.6,0) |- (norm5.east);
        
        % Cross Attention Connection (Encoder -> Decoder)
        % From Encoder Norm2 to Decoder MHA2
        \draw[arrow] (norm2.north) -- ++(0,0.2) -| (mha2.north); % This might look weird, standard is from top of encoder stack to side of MHA block
        % Let's adjustment routing:
        % Typically it goes from the output of the Encoder Stack (norm2) into the Multi-Head Attention of the Decoder (mha2).
        % Specifically into the Keys and Values. 
        % I'll draw a line from norm2 splitting to mha2.
        
        \draw[arrow] (norm2.east) -- ++(0.5,0) |- ([yshift=-0.2cm]mha2.west);
        % Also typically it enters from "below" or "side". The layout here has MHA2 above Norm3.
        % The standard diagram has the arrows coming from the side.
        
    \end{tikzpicture}
    \caption{Arquitetura do modelo Transformer. O modelo utiliza pilhas de camadas de atenção e feed-forward tanto no codificador (esquerda) quanto no decodificador (direita). Traduzido de \citet{204e3073870fae3d05bcbc2f6a8e263d9b72e776}.}
    \label{fig:transformer_block}
\end{figure}

Subsequentemente, a introdução de técnicas de estímulo ao raciocínio em etapas, conhecidas como \textit{Chain of Thought} (CoT), permitiu que esses modelos decompusessem problemas lógicos complexos em sequências de passos intermediários. Pesquisas indicam que a habilidade de raciocínio emerge naturalmente em modelos de grande escala quando instigados por demonstrações de pensamento estruturado \citep{1b6e810ce0afd0dd093f789d2b2742d047e316d5}. Tal avanço é fundamental para a transposição de requisitos de engenharia, que frequentemente exigem múltiplas etapas de dedução lógica antes da formalização matemática final.

\subsection{Integração de LLMs na Pesquisa Operacional}

A aplicação de LLMs no domínio da otimização tem evoluído da simples tradução de texto para código em direção à atuação direta como otimizadores. Metodologias baseadas em \textit{Optimization by PROmpting} (OPRO) utilizam o modelo de linguagem para gerar e refinar soluções iterativamente, integrando no contexto do \textit{prompt} o histórico de soluções anteriores e seus respectivos desempenhos \citep{f8a2dca1e8fe56e698984c077f7ff58d8ca867e9}. O processo pode ser resumido pela geração de uma nova solução $x_{t+1}$ baseada em um \textit{meta-prompt} $P_t$ que contém os pares $\{(x_i, f(x_i))\}_{i=1}^t$.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=2.5cm,
        auto,
        every node/.style={font=\scriptsize},
        proc/.style={rectangle, draw, fill=red!5, text width=2cm, align=center, minimum height=1cm, rounded corners},
        data/.style={trapezium, draw, fill=yellow!10, text width=1.5cm, align=center, trapezium left angle=70, trapezium right angle=110},
        arrow/.style={-latex', thick}
    ]
        % Ciclo OPRO
        \node[proc] (llm) {LLM Optimizer};
        \node[data, right=1.5cm of llm] (sol) {Solução ($x_t$)};
        \node[proc, below=1.5cm of sol] (eval) {Avaliador ($f(x)$)};
        \node[data, left=1.5cm of eval] (hist) {Histórico ($x_i, y_i$)};
        
        % Fluxo
        \draw[arrow] (llm) -- node[midway, above] {Gera} (sol);
        \draw[arrow] (sol) -- (eval);
        \draw[arrow] (eval) -- node[midway, below] {Score} (hist);
        \draw[arrow] (hist) -- node[midway, left] {Meta-Prompt} (llm);
        
        \node[above=0.2cm of llm] {\textbf{Optimization by Prompting}};

    \end{tikzpicture}
    \caption{Ciclo de otimização OPRO: O LLM gera soluções baseadas em um meta-prompt que contém o histórico de tentativas anteriores e suas avaliações, atuando como um algoritmo evolutivo guiado por linguagem. Adaptado de \citet{f8a2dca1e8fe56e698984c077f7ff58d8ca867e9}.}
    \label{fig:opro_cycle}
\end{figure}

Paralelamente, abordagens híbridas integram algoritmos evolutivos com o raciocínio semântico dos LLMs. O \textit{Reflective Evolution} (ReEvo) utiliza reflexões verbais como "gradientes linguísticos" para guiar a busca em espaços heurísticos, permitindo a evolução automática de algoritmos de busca sem intervenção humana direta \citep{be7a88babf78512b545f585517704cb597388cbc}.

A robustez desse processo de modelagem é fortalecida pela criação de bibliotecas de experiência autogeridas. O arcabouço \textit{AlphaOPT} propõe um ciclo de autoaperfeiçoamento onde o sistema reflete sobre falhas passadas para extrair \textit{insights} estruturados em quatro componentes: \textit{taxonomy} (classificação do erro), \textit{condition} (contexto de ocorrência), \textit{explanation} (causa raiz) e \textit{example} (solução corrigida) \citep{6f99bcc23e8308650dae64970980bdeae2a4f9d2}. Essa estrutura de memória é vital para evitar a reincidência de erros semânticos em formulações de engenharia crítica, onde a precisão das restrições é determinante para a viabilidade operacional.

\subsection{Sistemas de Diálogo e Interpretabilidade em Engenharia}

A aceitação de sistemas baseados em inteligência artificial no ambiente industrial depende intrinsecamente da transparência das decisões propostas. Iniciativas como o \textit{OptiChat} estabelecem sistemas de diálogo em linguagem natural que permitem a profissionais realizar diagnósticos de inviabilidade, análises de sensibilidade e explicações contrafatuais sem a necessidade de perícia em modelagem algébrica \citep{04eb39fb141f058081036a3c65610c59cd781792}. A Figura \ref{fig:optichat_overview} ilustra a arquitetura deste sistema.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=1.0cm,
        auto,
        every node/.style={font=\tiny},
        input/.style={rectangle, draw=blue!50, fill=blue!5, text width=2cm, align=center, rounded corners, minimum height=0.8cm},
        output/.style={rectangle, draw=green!50, fill=green!5, text width=2cm, align=center, rounded corners, minimum height=0.8cm},
        core/.style={rectangle, draw=purple!50, fill=purple!5, text width=1.5cm, align=center, rounded corners, minimum height=1.5cm, font=\bfseries\scriptsize},
        backend/.style={rectangle, draw=gray!80, thick, text width=2.2cm, align=center, rounded corners, minimum height=1cm},
        group/.style={draw=gray!50, dashed, inner sep=0.2cm, rounded corners}
    ]
        % (a) User Interface
        \node[core] (llm) {LLM};
        
        \node[input, left=1.0cm of llm, yshift=0.8cm] (agnostic) {Solution-agnostic\\Query};
        \node[input, left=1.0cm of llm, yshift=-0.8cm] (specific) {Solution-specific\\Query};
        
        \node[output, right=1.0cm of llm, yshift=0.8cm] (qualitative) {Qualitative\\Explanation};
        \node[output, right=1.0cm of llm, yshift=-0.8cm] (feedback) {Technical\\Feedback};
        
        % Conexões (a)
        \draw[-latex, blue!50, thick] (agnostic.east) -- (llm.west);
        \draw[-latex, blue!50, thick] (specific.east) -- (llm.west);
        \draw[-latex, green!50, thick] (llm.east) -- (qualitative.west);
        \draw[-latex, green!50, thick] (llm.east) -- (feedback.west);
        
        \node[above=1.5cm of llm, font=\bfseries\small] {(a) User Interface};

        % (b) Backend
        \node[below=1.5cm of llm] (interaction) {\textbf{Interaction}};
        \draw[<->, thick] (llm) -- (interaction);

        % Backend Label positioned clearly below Interaction
        \node[below=0.8cm of interaction, font=\bfseries\small] (lbl_backend) {(b) Backend System};

        % Backend Tools positioned relative to the Label
        \node[backend, below=0.5cm of lbl_backend] (funcs) {\textbf{Predefined Functions}\\Restore Feasibility\\Analyze Sensitivity};
        \node[backend, below=0.2cm of funcs] (codegen) {\textbf{Code Generation}\\Counterfactual Expl.\\Unexpected Failure};
        
        \node[backend, left=0.5cm of funcs, text width=1.8cm, minimum height=2.5cm] (software) {\textbf{Modeling Software}\\(Model Code)};
        \node[backend, right=0.5cm of funcs, text width=1.8cm, minimum height=2.5cm] (solver) {\textbf{Optimization Solver}\\(Description)};
        
    \end{tikzpicture}
    \caption{Visão geral do OptiChat. Entradas em azul (consultas), saídas em verde (explicações) e ferramentas de backend em cinza. Adaptado de \citet{04eb39fb141f058081036a3c65610c59cd781792}.}
    \label{fig:optichat_overview}
\end{figure} 


O sistema \textit{OptiMind} avança essa fronteira ao integrar conhecimentos específicos da Pesquisa Operacional para guiar o LLM na formulação de modelos de programação linear inteira mista (MILP). Ao utilizar estratégias de inferência multi-turno e síntese de erros baseada em classes de problemas, o \textit{OptiMind} eleva a acurácia das formulações ao mitigar erros comuns de modelagem através de ciclos de retroalimentação entre o modelo e o \textit{solver} \citep{92b39ce69cc1ee59aff8a92f30557728edc6ea32}.

Para assegurar a validade científica das formulações geradas, metodologias rigorosas de avaliação tornam-se indispensáveis. O \textit{ORGEval} propõe um arcabouço baseado em teoria dos grafos para avaliar a equivalência entre modelos, reduzindo a detecção de similaridade ao teste de isomorfismo de grafos. Essa abordagem permite uma avaliação robusta contra variações numéricas e estruturais, garantindo que o modelo gerado pelo LLM seja matematicamente equivalente à formulação de referência, independentemente de variações na nomenclatura de variáveis ou ordens de restrições \citep{3eee1fe6acf9760efa215130617a4f13d32b4962}. Tal rigor é essencial para sistemas que operam em infraestruturas críticas, onde a integridade semântica do modelo é um requisito de segurança inegociável.

% ============================================
% METODOLOGIA
% ============================================
\section{Metodologia}

A metodologia proposta para a execução desta pesquisa estrutura-se em fases incrementais, fundamentadas no desenvolvimento e na validação de um sistema multi-agente para suporte à decisão em problemas de engenharia crítica.

\subsection{Arquitetura do Sistema de Agentes Colaborativos}

O arcabouço computacional proposto fundamenta-se em uma arquitetura de Sistemas Multi-Agentes (MAS), projetada para operar em um ciclo fechado de formulação, crítica e autoajuste. A estrutura central é composta por dois agentes cognitivos principais que interagem entre si e com ferramentas externas de otimização, conforme detalhado a seguir:

\begin{itemize}
    \item \textbf{Agente Formulador (AF):} Este agente, baseado em modelos de linguagem de última geração, tem a função primordial de realizar o mapeamento semântico entre os requisitos expressos em linguagem natural e a sintaxe de linguagens de modelagem algébrica. O objetivo é traduzir a intenção do usuário para uma formulação matemática padrão dada por
    
    \begin{equation}
        \begin{aligned}
            & \min_{x}
            & & f(x) \\
            & \text{s.a.}
            & & g_i(x) \leq 0, \quad i = 1, \dots, m \\
            & & & h_j(x) = 0, \quad j = 1, \dots, p \\
            & & & x \in \mathcal{X}.
        \end{aligned}
    \end{equation}

    Para mitigar a ocorrência de erros lógicos na definição de $f(x)$, $g(x)$ e $h(x)$, o AF utiliza a técnica de \textit{Chain of Thought} (CoT) \citep{1b6e810ce0afd0dd093f789d2b2742d047e316d5}, permitindo que o modelo explicite os passos intermediários da dedução matemática antes da geração do código final.
    
    \item \textbf{Agente Crítico (AC):} Atuando como um mecanismo de supervisão, o AC avalia a consistência técnica das propostas geradas pelo AF. Inspirado no sistema \textit{OptiMind} \citep{92b39ce69cc1ee59aff8a92f30557728edc6ea32}, este agente integra retroalimentação direta de solvers de otimização (e.g., Gurobi) para identificar falhas de sintaxe e inviabilidade de modelos. Adicionalmente, o AC emprega métodos de verificação baseados em teoria dos grafos, conforme o arcabouço \textit{ORGEval} \citep{3eee1fe6acf9760efa215130617a4f13d32b4962}, para assegurar que a estrutura matemática gerada seja isomorfa às propriedades físicas e operacionais do sistema em estudo.
\end{itemize}

A sinergia entre esses agentes é mediada por uma \textbf{Biblioteca de Experiência Autogerida}, baseada na arquitetura \textit{AlphaOPT} \citep{6f99bcc23e8308650dae64970980bdeae2a4f9d2}. Este componente armazena taxonomias de erros e condições de falha observadas em iterações passadas, permitindo que o sistema realize uma evolução de biblioteca (\textit{Library Evolution}) para evitar a reincidência de alucinações semânticas em domínios de engenharia de energia. Esse mecanismo de memória é essencial para a robustez da solução, transformando falhas pontuais em aprendizado estruturado para o refinamento iterativo do modelo.

\subsection{Fluxo de Interação Human-in-the-Loop}

A interação entre o arcabouço multi-agente e o engenheiro de domínio processa-se por meio de um fluxo dinâmico de \textit{Human-in-the-loop}, fundamentado no princípio da adaptação corretiva com intervenção mínima \citep{074299c38fe2f099d970d92eafc592a6706035c6}. Este módulo é projetado para atuar como uma interface de diálogo inteligente, superando a rigidez dos sistemas de \textit{prompting} convencionais.

O processo inicia-se com a submissão de requisitos funcionais em linguagem natural. Caso o sistema identifique ambiguidades semânticas ou lacunas de informação que impeçam a formulação rigorosa, o Agente Crítico, em conjunto com um módulo de \textit{Active Learning}, interpele o usuário por meio de perguntas estratégicas. Este mecanismo de elucidação foca na extração de restrições implícitas e objetivos tácitos, transformando o processo de modelagem em uma cocriação assistida.

Inspirado na arquitetura do \textit{OptiChat} \citep{04eb39fb141f058081036a3c65610c59cd781792}, o sistema provê ao usuário ferramentas de diagnóstico de inviabilidade e análise de sensibilidade em linguagem natural. Quando o \textit{solver} retorna um resultado inesperado ou uma condição de \textit{infeasible}, o sistema traduz as causas técnicas (e.g., violação de limites de carregamento de linhas) em explicações qualitativas, permitindo que o engenheiro ajuste os parâmetros ou relaxe restrições de forma informada. Além disso, o fluxo contempla a geração de explicações contrafatuais (e.g., "o que ocorreria com o custo se o limite de geração solar fosse elevado em 10\%?"), consolidando a transparência indispensável para a tomada de decisão em sistemas críticos.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=3.0cm,
        auto,
        every node/.style={font=\scriptsize},
        human/.style={ellipse, draw=green!60!black, fill=green!5, thick, text width=2.5cm, align=center, minimum height=1.2cm},
        agent/.style={rectangle, draw=blue!60!black, fill=blue!5, thick, text width=2.8cm, align=center, rounded corners, minimum height=1.5cm},
        module/.style={rectangle, draw=orange!60!black, fill=orange!5, thick, text width=2.5cm, align=center, rounded corners, minimum height=1.2cm},
        db/.style={cylinder, draw=purple!60!black, fill=purple!5, thick, shape border rotate=90, aspect=0.25, text width=2cm, align=center, minimum height=1.5cm},
        arrow/.style={-latex, thick}
    ]

        % Nós Principais - Aumentando espaçamento horizontal e vertical
        \node[human] (eng) {\textbf{Engenheiro de Domínio}\\(Requisitos/Feedback)};
        \node[above=0.2cm of eng] {\textbf{Início}};
        
        \node[agent, right=4.5cm of eng] (form) {\textbf{Agente Formulador}\\(LLM + CoT)};
        
        \node[agent, below=3.5cm of form] (crit) {\textbf{Agente Crítico}\\(Verificação Semântica)};
        
        \node[module, left=3.5cm of crit] (solver) {\textbf{Solvers Externos}\\(Gurobi/CPLEX)};
        
        \node[module, above=1.5cm of form] (active) {\textbf{Módulo de}\\Active Learning};
        
        \node[db, right=2.0cm of crit] (mem) {\textbf{Biblioteca de}\\Experiência\\(Taxonomia de Erros)};

        % Conexões - Fluxo Principal
        \draw[arrow] (eng) -- node[midway, above] {Linguagem Natural} (form);
        \draw[arrow] (form) -- node[midway, right] {Draft de Modelo} (crit);
        
        % Solver <-> Critico (Separando ida e volta)
        \draw[arrow] ([yshift=0.1cm]crit.west) -- node[midway, above] {Código} ([yshift=0.1cm]solver.east);
        \draw[arrow] ([yshift=-0.1cm]solver.east) -- node[midway, below] {Status/Log} ([yshift=-0.1cm]crit.west);
        
        % Loops de Refinamento (Curva para esquerda para não bater no texto Draft)
        \draw[arrow, red!70!black, dashed] (crit.north west) to[bend left=30] node[midway, left] {Correção ({OptiMind})} (form.south west);
        
        % Active Learning (Ambiguidades)
        \draw[arrow, orange!70!black] (form.north) -- (active.south);
        \draw[arrow, orange!70!black] (active.west) -| node[pos=0.25, above] {Perguntas de Elucidação} (eng.north);
        
        % Memória (AlphaOPT)
        \draw[arrow, purple!70!black] (mem) -- (crit);
        \draw[arrow, purple!70!black] (mem) |- (form);
        \draw[arrow, purple!70!black, dashed] (crit) -- (mem);

        % Saída Final - Rota por BAIXO para evitar colisão com Solver
        \draw[arrow, green!60!black, double] (crit.south) -- ++(0,-0.8) -| node[pos=0.25, above] {Solução Explicável} (eng.south);

    \end{tikzpicture}
    \caption{Fluxograma detalhado da arquitetura proposta. O fluxo integra (1) \textit{Active Learning} para resolução de ambiguidades, (2) Ciclo de refinamento entre Formulador e Crítico assistido por Solvers, e (3) Uma Biblioteca de Experiência persistente para aprendizado contínuo, inspirado em \citet{6f99bcc23e8308650dae64970980bdeae2a4f9d2} e \citet{074299c38fe2f099d970d92eafc592a6706035c6}.}
    \label{fig:fluxo_agentes}
\end{figure}

\subsection{Cenário de Aplicação e Validação Experimental}

A validação do arcabouço proposto será conduzida em cenários realistas da engenharia de energia elétrica, com foco em problemas de alta complexidade e impacto sistêmico. Serão selecionados dois estudos de caso principais: o planejamento da expansão de sistemas de transmissão sob incertezas de demanda e a otimização do despacho de geração renovável intermitente. Tais problemas exigem a manipulação de grandes volumes de restrições técnicas (e.g., leis de Kirchhoff, limites de estabilidade térmica) que servem de base ideal para testar a precisão semântica dos agentes cognitivos.

Para a implementação dos modelos, serão utilizadas ferramentas de modelagem algébrica de código aberto, especificamente o ecossistema Pyomo em ambiente Python, integrando solvers comerciais de alto desempenho como Gurobi e CPLEX. A avaliação da eficácia do sistema basear-se-á em métricas rigorosas de desempenho e confiabilidade:

\begin{itemize}
    \item \textbf{Taxa de Viabilidade Semântica:} Medida pela proporção de modelos gerados que são sintaticamente corretos e fisicamente consistentes com os requisitos de engenharia.
    \item \textbf{Equivalência Estrutural:} Utilização do arcabouço \textit{ORGEval} \citep{3eee1fe6acf9760efa215130617a4f13d32b4962} para verificar, via isomorfismo de grafos, se a formulação gerada pelo LLM é matematicamente equivalente ao modelo de referência estabelecido por especialistas humanos.
    \item \textbf{Eficiência de Modelagem:} Comparação temporal entre o processo de formulação assistida por agentes e o método de modelagem manual convencional.
\end{itemize}

Complementarmente, será realizada uma análise qualitativa da explicabilidade das soluções, avaliando a capacidade do sistema em fornecer justificativas técnicas que atendam aos requisitos de transparência exigidos por operadores de sistemas elétricos.

\clearpage

% ============================================
% CRONOGRAMA
% ============================================
\section{Cronograma}

O projeto de pesquisa será desenvolvido ao longo de um período de 48 meses, organizado em oito semestres letivos. O planejamento das atividades prioriza o cumprimento dos créditos obrigatórios e a revisão bibliográfica inicial, seguidos pelas etapas de desenvolvimento, experimentação e redação da tese.

\begin{table}[ht]
\centering
\small
\begin{tabularx}{\textwidth}{|X|c|c|c|c|c|c|c|c|}
\hline
\textbf{Atividades / Semestre} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\ \hline
Créditos e Revisão Bibliográfica Sistemática & X & X & & & & & & \\ \hline
Concepção da Arquitetura Multi-Agente & & X & X & & & & & \\ \hline
Desenv. Agente Formulador e Crítico (Prompt Engineering) & & & X & X & & & & \\ \hline
Implementação do Módulo Active Learning e Interface & & & & X & X & & & \\ \hline
Integração com Solvers e Biblioteca de Experiência & & & & & X & X & & \\ \hline
Exame de Qualificação & & & & & X & & & \\ \hline
Estudos de Caso: Expansão e Despacho (Validação) & & & & & & X & X & \\ \hline
Análise Comparativa (ORGEval) e Escrita de Artigos & & & & & & X & X & X \\ \hline
Redação Final e Defesa da Tese & & & & & & & & X \\ \hline
\end{tabularx}
\caption{Cronograma de execução das atividades de doutorado previstas para o período de 8 semestres letivos.}
\end{table}

\clearpage

% ============================================
% REFERÊNCIAS
% ============================================
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
